{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA) - Heart Disease Risk Dataset\n",
        "\n",
        "This notebook contains a comprehensive exploration of the BRFSS dataset used for heart disease risk prediction.\n",
        "\n",
        "## Objectives:\n",
        "1. Understand the dataset structure and content\n",
        "2. Analyze missing values patterns\n",
        "3. Extract and link feature labels from HTML codebook\n",
        "4. Explore feature correlations with target variable\n",
        "5. Identify relevant feature groups for modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import bs4\n",
        "import re\n",
        "\n",
        "# Configure plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training data\n",
        "df = pd.read_csv(\"data/train.csv\")\n",
        "\n",
        "# Basic information\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Number of features: {df.shape[1]}\")\n",
        "print(f\"Number of samples: {df.shape[0]}\")\n",
        "print(f\"\\nTarget variable: {df.columns[-1]}\")\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(df['TARGET'].value_counts())\n",
        "print(f\"\\nClass balance: {df['TARGET'].value_counts(normalize=True)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Extract Feature Labels from HTML Codebook\n",
        "\n",
        "The dataset comes with an HTML codebook containing detailed descriptions of each feature. We parse this to understand what each column represents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "html_file = \"data/USCODE22_LLCP_102523.HTML\"\n",
        "\n",
        "# Read and parse HTML\n",
        "with open(html_file, encoding=\"latin-1\") as f:\n",
        "    html = f.read()\n",
        "\n",
        "soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "# Extract question information\n",
        "questions = []\n",
        "\n",
        "for td in soup.find_all(\"td\", class_=\"l m linecontent\"):\n",
        "    text = td.get_text(separator=\" \", strip=True)\n",
        "    text = text.replace(\"\\xa0\", \" \")  \n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "    # Extract different fields using regex\n",
        "    label_match = re.search(r\"Label:\\s(.*?)\\s+(?:Section Name:|Core Section Name:)\", text, re.IGNORECASE)\n",
        "    section_name_match = re.search(r\"(?:Section Name:|Core Section Name:)\\s(.*?)\\s+(?:Section Number:|Core Section Number:|Module Number:)\", text, re.IGNORECASE)\n",
        "    section_number_match = re.search(r\"(?:Section Number:|Core Section Number:|Module Number:)\\s*([0-9A-Za-z]+)\", text, re.IGNORECASE)\n",
        "    sas_match = re.search(r\"SAS Variable Name:\\s*([A-Za-z0-9_]+)\", text, re.IGNORECASE)\n",
        "\n",
        "    questions.append({\n",
        "        \"Label\": label_match.group(1).strip() if label_match else \"\",\n",
        "        \"Section Name\": section_name_match.group(1).strip() if section_name_match else \"\",\n",
        "        \"Section Number\": section_number_match.group(1).strip() if section_number_match else \"\", \n",
        "        \"SAS_Variable_Name\": sas_match.group(1).strip() if sas_match else \"\"\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "labels_df = pd.DataFrame(questions)\n",
        "\n",
        "# Save for later use\n",
        "labels_df.to_csv(\"data/labels_questions.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"Extracted {len(labels_df)} feature descriptions\")\n",
        "print(f\"\\nNumber of unique sections: {labels_df['Section Name'].nunique()}\")\n",
        "print(f\"\\nSample of extracted data:\")\n",
        "labels_df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Missing Values Analysis\n",
        "\n",
        "Understanding patterns in missing data is crucial for preprocessing decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate missing value percentages\n",
        "missing_percent = df.isna().mean() * 100\n",
        "missing_percent = missing_percent.sort_values(ascending=False)\n",
        "\n",
        "# Display statistics\n",
        "print(\"Missing Values Statistics:\")\n",
        "print(f\"Columns with 100% missing: {(missing_percent == 100).sum()}\")\n",
        "print(f\"Columns with >90% missing: {(missing_percent > 90).sum()}\")\n",
        "print(f\"Columns with >50% missing: {(missing_percent > 50).sum()}\")\n",
        "print(f\"Columns with 0% missing: {(missing_percent == 0).sum()}\")\n",
        "\n",
        "# Show top features with missing values\n",
        "print(f\"\\nTop 20 features with most missing values:\")\n",
        "missing_percent.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize distribution of missing values\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(missing_percent, bins=50, edgecolor='black', alpha=0.7)\n",
        "plt.xlabel('Percentage of Missing Values (%)')\n",
        "plt.ylabel('Number of Features')\n",
        "plt.title('Distribution of Missing Values Across Features')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# Group by ranges\n",
        "bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "labels = ['0-10%', '10-20%', '20-30%', '30-40%', '40-50%', '50-60%', '60-70%', '70-80%', '80-90%', '90-100%']\n",
        "categories = pd.cut(missing_percent, bins=bins, labels=labels, include_lowest=True)\n",
        "category_counts = categories.value_counts().sort_index()\n",
        "\n",
        "plt.bar(range(len(category_counts)), category_counts.values, edgecolor='black', alpha=0.7)\n",
        "plt.xticks(range(len(category_counts)), category_counts.index, rotation=45, ha='right')\n",
        "plt.xlabel('Missing Value Range')\n",
        "plt.ylabel('Number of Features')\n",
        "plt.title('Features Grouped by Missing Value Percentage')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Correlation with Target\n",
        "\n",
        "Identify which features are most correlated with the target variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to numeric for correlation\n",
        "df_num = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Calculate correlation with target\n",
        "target_col = 'TARGET'\n",
        "corr_with_target = df_num.corr(numeric_only=True)[target_col].drop(labels=[target_col], errors='ignore')\n",
        "\n",
        "# Sort by absolute correlation\n",
        "corr_sorted = corr_with_target.abs().sort_values(ascending=False)\n",
        "\n",
        "print(f\"Features with |correlation| > 0.1: {(corr_sorted > 0.1).sum()}\")\n",
        "print(f\"\\nTop 20 features correlated with target:\")\n",
        "print(pd.DataFrame({\n",
        "    'Feature': corr_sorted.head(20).index,\n",
        "    'Correlation': corr_with_target[corr_sorted.head(20).index].values,\n",
        "    'Abs Correlation': corr_sorted.head(20).values\n",
        "}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize correlation with target\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_n = 25\n",
        "top_features = corr_sorted.head(top_n).index\n",
        "top_corr = corr_with_target[top_features]\n",
        "\n",
        "colors = ['red' if x < 0 else 'green' for x in top_corr.values]\n",
        "plt.barh(range(len(top_corr)), top_corr.values, color=colors, alpha=0.7, edgecolor='black')\n",
        "plt.yticks(range(len(top_corr)), top_features)\n",
        "plt.xlabel('Correlation with Target')\n",
        "plt.title(f'Top {top_n} Features Correlated with Heart Disease Risk')\n",
        "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analysis by Feature Section\n",
        "\n",
        "Group features by their section to understand which categories are most informative.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove columns that are 100% NaN for analysis\n",
        "cols_all_nan = df.columns[df.isna().all()].tolist()\n",
        "df_clean = df.drop(cols_all_nan, axis=1)\n",
        "labels_clean = labels_df[~labels_df['SAS_Variable_Name'].isin(cols_all_nan)].reset_index(drop=True)\n",
        "\n",
        "print(f\"Removed {len(cols_all_nan)} columns with 100% NaN\")\n",
        "print(f\"Remaining features: {df_clean.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute NaN percentage for each feature\n",
        "nan_percent = df_clean.isna().mean() * 100\n",
        "nan_percent = nan_percent.reset_index()\n",
        "nan_percent.columns = [\"SAS_Variable_Name\", \"NaN_percent\"]\n",
        "\n",
        "# Compute correlation for each feature\n",
        "corrs = []\n",
        "for col in df_clean.columns:\n",
        "    if col == target_col:\n",
        "        continue\n",
        "    try:\n",
        "        if pd.api.types.is_numeric_dtype(df_clean[col]):\n",
        "            corr = df_clean[col].corr(df_clean[target_col])\n",
        "            corrs.append((col, corr))\n",
        "        else:\n",
        "            corrs.append((col, np.nan))\n",
        "    except Exception:\n",
        "        corrs.append((col, np.nan))\n",
        "\n",
        "corr_df = pd.DataFrame(corrs, columns=[\"SAS_Variable_Name\", \"corr_with_target\"])\n",
        "\n",
        "# Merge with labels\n",
        "merged = (\n",
        "    nan_percent\n",
        "    .merge(corr_df, on=\"SAS_Variable_Name\", how=\"left\")\n",
        "    .merge(labels_clean[[\"SAS_Variable_Name\", \"Section Name\"]],\n",
        "           on=\"SAS_Variable_Name\", how=\"left\")\n",
        ")\n",
        "\n",
        "# Aggregate by section\n",
        "section_summary = merged.groupby(\"Section Name\").agg(\n",
        "    mean_nan_percent=(\"NaN_percent\", \"mean\"),\n",
        "    mean_abs_corr=(\"corr_with_target\", lambda x: np.nanmean(np.abs(x))),\n",
        "    num_features=(\"SAS_Variable_Name\", \"count\")\n",
        ").sort_values(\"mean_abs_corr\", ascending=False)\n",
        "\n",
        "print(\"Section Summary (sorted by mean absolute correlation):\")\n",
        "print(section_summary.head(15))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize section importance\n",
        "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Sort by correlation for better visualization\n",
        "section_summary_sorted = section_summary.sort_values(\"mean_abs_corr\")\n",
        "\n",
        "# Bar plot for mean NaN percentage\n",
        "ax1.barh(range(len(section_summary_sorted)), \n",
        "         section_summary_sorted['mean_nan_percent'], \n",
        "         color=\"skyblue\", alpha=0.7, label=\"Mean % NaN\")\n",
        "ax1.set_xlabel(\"Average Missing Values (%)\", color=\"skyblue\")\n",
        "ax1.set_ylabel(\"Section Name\")\n",
        "ax1.set_yticks(range(len(section_summary_sorted)))\n",
        "ax1.set_yticklabels(section_summary_sorted.index, fontsize=8)\n",
        "ax1.tick_params(axis='x', labelcolor=\"skyblue\")\n",
        "\n",
        "# Overlay line plot for correlation\n",
        "ax2 = ax1.twiny()\n",
        "ax2.plot(section_summary_sorted['mean_abs_corr'], \n",
        "         range(len(section_summary_sorted)),\n",
        "         color=\"darkred\", marker=\"o\", linewidth=2, markersize=5, label=\"Mean |corr|\")\n",
        "ax2.set_xlabel(\"Mean Absolute Correlation with Target\", color=\"darkred\")\n",
        "ax2.tick_params(axis='x', labelcolor=\"darkred\")\n",
        "\n",
        "plt.title(\"Feature Sections: Missing Values vs. Correlation with Target\", pad=20)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Correlation Matrix of Selected Features\n",
        "\n",
        "Examine correlations between the most relevant features (|correlation| > 0.1 with target).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select features with high correlation and low missing values\n",
        "high_corr_features = corr_with_target[abs(corr_with_target) > 0.1].index.tolist()\n",
        "nan_pct_dict = nan_percent.set_index(\"SAS_Variable_Name\")[\"NaN_percent\"].to_dict()\n",
        "\n",
        "# Filter features with < 70% missing values\n",
        "selected_for_viz = [f for f in high_corr_features if nan_pct_dict.get(f, 100) < 70]\n",
        "\n",
        "print(f\"Selected {len(selected_for_viz)} features for correlation matrix visualization\")\n",
        "print(f\"(|correlation| > 0.1 and < 70% missing values)\")\n",
        "\n",
        "# Compute correlation matrix\n",
        "if len(selected_for_viz) > 1:\n",
        "    corr_matrix = df_clean[selected_for_viz + [target_col]].corr()\n",
        "    \n",
        "    # Visualize\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
        "    sns.heatmap(corr_matrix, mask=mask, cmap=\"vlag\", center=0, \n",
        "                vmin=-1, vmax=1, square=True, \n",
        "                linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "    plt.title(\"Correlation Matrix of Selected Features\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Key Insights\n",
        "\n",
        "### Dataset Characteristics:\n",
        "1. **Imbalanced Dataset**: Only ~9% of samples have positive heart disease risk\n",
        "2. **High Dimensionality**: 325 features with varying levels of missing data\n",
        "3. **Missing Data Patterns**: Many features have >90% missing values (likely optional questions)\n",
        "\n",
        "### Most Informative Feature Categories:\n",
        "- **Demographics** (Age variables): Strongest correlation with target\n",
        "- **Health Status**: General health perception\n",
        "- **Chronic Conditions**: Diabetes, arthritis\n",
        "- **Lifestyle Factors**: Smoking, exercise\n",
        "\n",
        "### Recommendations for Modeling:\n",
        "1. Focus on features with |correlation| > 0.1 (23 features)\n",
        "2. Remove columns with 100% missing values\n",
        "3. Handle class imbalance with class weighting or resampling\n",
        "4. Use imputation strategies for remaining missing values\n",
        "5. Consider feature engineering from highly correlated groups\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
